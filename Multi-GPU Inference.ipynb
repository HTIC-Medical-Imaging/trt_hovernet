{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a2736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f5c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images 1050\n"
     ]
    }
   ],
   "source": [
    "Image_size = 256\n",
    "storage_dir = \"./storage\"\n",
    "file_list = os.listdir(storage_dir+\"/cache_\"+str(Image_size))\n",
    "print(\"Number of Images\",len(file_list))\n",
    "pics = [ storage_dir + \"/cache_\"+str(Image_size) + \"/\" +str(i) for i in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23858a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pics = np.asarray(Image.open(pics[0]))\n",
    "brain_tiles = np_pics.reshape(1,3,Image_size,Image_size)\n",
    "for i in range(65):\n",
    "    img = np.asarray(Image.open(pics[i+1]))\n",
    "    if (img.shape == (256, 256, 3)):\n",
    "        brain_tiles = np.concatenate((brain_tiles,img.reshape(1,3,Image_size,Image_size)),axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2f79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = torch.from_numpy(brain_tiles).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfc8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = brain_tiles[:1024,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b55518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_tiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbe50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 2\n",
    "chunk = brain_tiles.shape[0]//num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580843d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_batches = [brain_tiles[i:i+chunk,:,:,:] for i in range(0,brain_tiles.shape[0],chunk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9471ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brain_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f360be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 256, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_batches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f1e041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 256, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_batches[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24fe03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import TensorRT.inference as inf\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11036e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "import nvidia_smi\n",
    "nvidia_smi.nvmlInit()\n",
    "from ctypes import cdll, c_char_p\n",
    "libcudart = cdll.LoadLibrary('libcudart.so')\n",
    "libcudart.cudaGetErrorString.restype = c_char_p\n",
    "def cudaSetDevice(device_idx):\n",
    "    ret = libcudart.cudaSetDevice(device_idx)\n",
    "    if ret != 0:\n",
    "        error_string = libcudart.cudaGetErrorString(ret)\n",
    "        raise RuntimeError(\"cudaSetDevice: \" + error_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2360fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf(context,h_input, d_input, h_output, d_output, stream,image):\n",
    "    inf.load_images_to_buffer(images, h_input)\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    context.execute_v2(bindings=[int(d_input), int(d_output)])\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    \n",
    "def run_batch_inf(engine,images,batch_sizes=8):\n",
    "    h_input, d_input, h_output, d_output, stream = inf.allocate_buffers(engine,1,trt.float32)\n",
    "    context = engine.create_execution_context()\n",
    "    input_shape = (batch_sizes,3,256,256)\n",
    "    context.set_binding_shape(0, input_shape)\n",
    "    for i in range(0,images.shape[0],batch_size):\n",
    "        run_inf(context,h_input, d_input, h_output, d_output, stream,images[i:i+batch_size,:,:,:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e261210",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(min_severity =trt.ILogger.INTERNAL_ERROR)\n",
    "def load_engine(engine_file_path):\n",
    "    assert os.path.exists(engine_file_path)\n",
    "    print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3f79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b80f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24f4df4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brain_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac0b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file model.plan\n",
      "Reading engine from file model.plan\n"
     ]
    }
   ],
   "source": [
    "cudaSetDevice(0)\n",
    "engines.append(load_engine(\"model.plan\"))\n",
    "cudaSetDevice(1)\n",
    "engines.append(load_engine(\"model.plan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23cc8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(2) as executor:\n",
    "    results = executor.map(run_batch_inf,engines,brain_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc7a7f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuMemHostAlloc failed: invalid device context",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn [14], line 8\u001b[0m, in \u001b[0;36mrun_batch_inf\u001b[0;34m(engine, images, batch_sizes)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_batch_inf\u001b[39m(engine,images,batch_sizes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     h_input, d_input, h_output, d_output, stream \u001b[38;5;241m=\u001b[39m \u001b[43minf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate_buffers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     context \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mcreate_execution_context()\n\u001b[1;32m     10\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m (batch_sizes,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n",
      "File \u001b[0;32m/workspace/trt_hovernet/TensorRT/inference.py:25\u001b[0m, in \u001b[0;36mallocate_buffers\u001b[0;34m(engine, batch_size, data_type)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mThis is the function to allocate buffers for input and output in the device\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m h_input_1 \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpagelocked_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvolume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_binding_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnptype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmem_flags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m h_output \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mpagelocked_empty(batch_size \u001b[38;5;241m*\u001b[39m trt\u001b[38;5;241m.\u001b[39mvolume(engine\u001b[38;5;241m.\u001b[39mget_binding_shape(\u001b[38;5;241m1\u001b[39m)), dtype\u001b[38;5;241m=\u001b[39mtrt\u001b[38;5;241m.\u001b[39mnptype(data_type))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Allocate device memory for inputs and outputs.\u001b[39;00m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuMemHostAlloc failed: invalid device context"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "880fa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    print(type(r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e896d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x7f6bc32bb0b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b184dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
