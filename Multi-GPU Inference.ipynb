{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a2736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f5c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images 1029\n"
     ]
    }
   ],
   "source": [
    "Image_size = 256\n",
    "storage_dir = \"./storage\"\n",
    "file_list = os.listdir(storage_dir+\"/cache_\"+str(Image_size))\n",
    "print(\"Number of Images\",len(file_list))\n",
    "pics = [ storage_dir + \"/cache_\"+str(Image_size) + \"/\" +str(i) for i in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23858a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pics = np.asarray(Image.open(pics[0]))\n",
    "brain_tiles = np_pics.reshape(1,4,Image_size,Image_size)\n",
    "for i in range(1028):\n",
    "    img = np.asarray(Image.open(pics[i+1]))\n",
    "    if (img.shape == (256, 256, 3)):\n",
    "        brain_tiles = np.concatenate((brain_tiles,img.reshape(1,4,Image_size,Image_size)),axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2f79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = torch.from_numpy(brain_tiles).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfc8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = brain_tiles[:1024,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b55518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_tiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6424dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = 2\n",
    "chunk = brain_tiles.shape[0]//num_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cee43bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_batches = [brain_tiles[i:i+chunk,:,:,:] for i in range(0,brain_tiles.shape[0],chunk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac549a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brain_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8974df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_batches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d343b087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_batches[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdf66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda import driver\n",
    "\n",
    "driver.init()\n",
    "ngpus = driver.Device.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d0dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663294a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx=[driver.Device(gpuid).make_context() for gpuid in range(ngpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423abac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pycuda._driver.Context at 0x7fd0497c3270>,\n",
       " <pycuda._driver.Context at 0x7fd0497c3040>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f54d5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devices = [elt.get_device() for elt in ctx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b46c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b13a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devices[1].pci_bus_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde4328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e53d6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pycuda.autoinit.device.pci_bus_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01fb8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import TensorRT.inference as inf\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ab2ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "\n",
    "import nvidia_smi\n",
    "nvidia_smi.nvmlInit()\n",
    "from ctypes import cdll, c_char_p\n",
    "libcudart = cdll.LoadLibrary('libcudart.so')\n",
    "libcudart.cudaGetErrorString.restype = c_char_p\n",
    "def cudaSetDevice(device_idx):\n",
    "    ret = libcudart.cudaSetDevice(device_idx)\n",
    "    if ret != 0:\n",
    "        error_string = libcudart.cudaGetErrorString(ret)\n",
    "        raise RuntimeError(\"cudaSetDevice: \" + error_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e70271b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf(context,h_input, d_input, h_output, d_output, stream,image,gpu_id):\n",
    "    ctx[gpu_id].push()\n",
    "    inf.load_images_to_buffer(image, h_input)\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    context.execute_v2(bindings=[int(d_input), int(d_output)])\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    \n",
    "def run_batch_inf(engine,images,gpu_id,batch_sizes=4):\n",
    "    \n",
    "    h_input, d_input, h_output, d_output, stream = inf.allocate_buffers(engine,1,trt.float32,ctx[gpu_id])\n",
    "    context = engine.create_execution_context()\n",
    "    input_shape = (batch_sizes,3,256,256)\n",
    "    context.set_binding_shape(0, input_shape)\n",
    "    print(images.shape)\n",
    "    for i in range(0,images.shape[0],batch_sizes):\n",
    "        run_inf(context,h_input, d_input, h_output, d_output, stream,images[i:i+batch_sizes,:,:,:],gpu_id)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e261210",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(min_severity =trt.ILogger.INTERNAL_ERROR)\n",
    "def load_engine(engine_file_path):\n",
    "    assert os.path.exists(engine_file_path)\n",
    "    print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e3e2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44c31f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52967c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brain_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32846bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hovernet_256_4_fp16.plan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac0b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file hovernet_256_4_fp16.plan\n",
      "Reading engine from file hovernet_256_4_fp16.plan\n"
     ]
    }
   ],
   "source": [
    "cudaSetDevice(0)\n",
    "engines.append(load_engine(model_name))\n",
    "cudaSetDevice(1)\n",
    "engines.append(load_engine(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d1f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_897/375445964.py:13: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, input_shape)\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(2) as executor:\n",
    "    results = executor.map(run_batch_inf,engines,brain_batches,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85ccd18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(r)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33818777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938/850779005.py:13: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, input_shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 256, 256])\n",
      "torch.Size([512, 3, 256, 256])\n",
      "CPU times: user 3.65 s, sys: 62.5 ms, total: 3.71 s\n",
      "Wall time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(2):\n",
    "    run_batch_inf(engines[i%2],brain_batches[i%2],i%2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "805ad2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pycuda._driver.Context at 0x7fd0497c3270>,\n",
       " <pycuda._driver.Context at 0x7fd0497c3040>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e0974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
