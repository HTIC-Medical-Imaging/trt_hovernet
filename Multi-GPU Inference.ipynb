{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa5bc491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "url  = \"https://drive.google.com/file/d/1Hb7Lgo5vtbAtr36fq6knylSiATlJRDS6/view?usp=share_link\"\n",
    "output = \"./storage/jp2cache/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "storage_dir = \"./storage\"\n",
    "\n",
    "if not os.path.exists(storage_dir + \"/jp2cache\"):\n",
    "    os.makedirs(storage_dir + \"/jp2cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9b69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Hb7Lgo5vtbAtr36fq6knylSiATlJRDS6\n",
      "To: /workspace/trt_hovernet/storage/jp2cache/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 13.0G/13.0G [04:10<00:00, 52.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./storage/jp2cache/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce20ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Multi-GPU Inference.ipynb'   hovernet_256_8_TF32.plan\r\n",
      " README.md\t\t      hovernet_256_8_fp16.plan\r\n",
      " TensorRT\t\t      hovernet_fast_pannuke_type_tf2pytorch.tar\r\n",
      " TensorRT_benchmarks.ipynb    jp2tileaccesor\r\n",
      " build.sh\t\t      models\r\n",
      " dockerfile\t\t      run_utils\r\n",
      " hovernet_256_16_TF32.plan    setup.sh\r\n",
      " hovernet_256_16_best.plan    setup_base\r\n",
      " hovernet_256_16_fp16.plan    storage\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341a08bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 5944, 'position_index': 1708, 'jp2Path': '/data/storageIIT/humanbrain/analytics/37/NISL/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2', 'pngPathLow': '/data/storageIIT/humanbrain/analytics/37/NISL/B_37_FB3-SL_570-ST_NISL-SE_1708_thumbnail.jpg', 'width': 81590, 'height': 83590, 'series': 10, 'rigidrotation': 90, 'notes': None}{'brainid': 15, 'seriesType': 'NISSL', 'secnumber': 1708, 'modes': {'jp2': False, 'iip': True, 'mmap': False, 'tif': False}}\n"
     ]
    }
   ],
   "source": [
    "from jp2tileaccesor.multi_res_Tiling import SectionProxy, TileAccessor, Span\n",
    "proxy_lossless = SectionProxy(15, \"NISSL\", 1708)\n",
    "\n",
    "print(proxy_lossless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "861b941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./storage/jp2cache/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_lossless.check_local_jp2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "898d28c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'proxy': \"{'id': 5944, 'position_index': 1708, 'jp2Path': '/data/storageIIT/humanbrain/analytics/37/NISL/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2', 'pngPathLow': '/data/storageIIT/humanbrain/analytics/37/NISL/B_37_FB3-SL_570-ST_NISL-SE_1708_thumbnail.jpg', 'width': 81590, 'height': 83590, 'series': 10, 'rigidrotation': 90, 'notes': None}{'brainid': 15, 'seriesType': 'NISSL', 'secnumber': 1708, 'modes': {'jp2': True, 'iip': True, 'mmap': False, 'tif': False}}\", 'resolution': 0, 'imagespan': Span(w=81590, h=83590), 'tilespan': Span(w=256, h=256), 'ntiles': 104313, 'ntiles_c': 319, 'ntiles_r': 327}\n"
     ]
    }
   ],
   "source": [
    "Image_size = 256\n",
    "size = Span(Image_size,Image_size)\n",
    "accessor = TileAccessor(proxy_lossless, 0, tilespan = size, use_iip = False)\n",
    "print(accessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72a2736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tiles = 64\n",
    "t=0\n",
    "if not os.path.exists(storage_dir + \"/cache_\" + str(Image_size)):\n",
    "    os.makedirs(storage_dir + \"/cache_\" + str(Image_size))\n",
    "\n",
    "for i in range(0,accessor.ntiles):\n",
    "    if t >= num_tiles:\n",
    "        break\n",
    "    tile = accessor[np.random.randint(accessor.ntiles)]\n",
    "    if tile[0].shape == (256, 256, 3):\n",
    "        plt.imsave(storage_dir+\"/cache_\"+str(Image_size) + \"/\"+str(i)+\".png\",tile[0])\n",
    "        t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48f5c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images 64\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(storage_dir+\"/cache_\"+str(Image_size))\n",
    "print(\"Number of Images\",len(file_list))\n",
    "pics = [ storage_dir + \"/cache_\"+str(Image_size) + \"/\" +str(i) for i in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23858a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pics = np.asarray(Image.open(pics[0]))\n",
    "brain_tiles = np_pics.reshape(1,4,Image_size,Image_size)\n",
    "for i in range(len(file_list)-1):\n",
    "    brain_tiles = np.concatenate((brain_tiles,np.asarray(Image.open(pics[i+1])).reshape(1,4,Image_size,Image_size)),axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f2f79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = torch.from_numpy(brain_tiles).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdfc8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_tiles = brain_tiles[:,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b55518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 256, 256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_tiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab4b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e261210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorRT.inference as inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44779612",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(min_severity =trt.ILogger.INTERNAL_ERROR)\n",
    "def load_engine(engine_file_path):\n",
    "    assert os.path.exists(engine_file_path)\n",
    "    print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "    with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "754b1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_files = {16 : [\"hovernet_256_16_TF32.plan\",\"hovernet_256_16_best.plan\",\"hovernet_256_16_fp16.plan\"], 8 : [\"hovernet_256_8_TF32.plan\",\"hovernet_256_8_fp16.plan\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b721ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53daa08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803e1ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 11:08:11,085\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.10', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '172.17.0.2', 'raylet_ip_address': '172.17.0.2', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-01-16_11-08-09_490333_18737/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-01-16_11-08-09_490333_18737/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-01-16_11-08-09_490333_18737', 'metrics_export_port': 58415, 'gcs_address': '172.17.0.2:55691', 'address': '172.17.0.2:55691', 'dashboard_agent_listen_port': 52365, 'node_id': '00978d2df01e794fa5719aac058b52c7db348f213126fe34ede77767'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:08:21,046 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:08:31,050 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:08:41,052 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:08:51,055 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:01,058 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:11,061 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:11,077 E 18917 18917] (raylet) node_manager.cc:3097: 29 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 00978d2df01e794fa5719aac058b52c7db348f213126fe34ede77767, IP: 172.17.0.2) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.0.2`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:21,064 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:31,069 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:41,072 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-01-16 11:09:51,076 E 18917 18958] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-01-16_11-08-09_490333_18737 is over 95% full, available space: 0; capacity: 200512491520. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd86745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10ae4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f47ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b8981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf654e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ceef854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nvidia_smi\n",
    "nvidia_smi.nvmlInit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cd6f1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia_smi.nvmlUnitGetCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cc981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ac0b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf(h_input_1, d_input_1, h_output, d_output, stream,images):\n",
    "    inf.load_images_to_buffer(images, h_input_1)\n",
    "    cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
    "    context.execute_v2(bindings=[int(d_input_1), int(d_output)])\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    return h_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fa51c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import pycuda.autoinit \n",
    "import nvidia_smi\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "results_run_engine = {}\n",
    "results_time_in = {}\n",
    "results_time_out = {}\n",
    "results_time_load = {}\n",
    "results_time_gpu_engine = {}\n",
    "Batch_sizes = [8,16]\n",
    "\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "for j in Batch_sizes:\n",
    "    batch_size = j\n",
    "    for path_plan in engine_files[j]:\n",
    "        \n",
    "        res = []\n",
    "        res2 = []\n",
    "        res3 = []\n",
    "        res4 = []\n",
    "        res_gpu = []\n",
    "        res_mem = []\n",
    "        res_pwr = []\n",
    "        engine = load_engine(path_plan)\n",
    "        h_input_1, d_input_1, h_output, d_output, stream = inf.allocate_buffers(engine,1,trt.float32)\n",
    "        with engine.create_execution_context() as context:\n",
    "            for i in range(0,brain_tiles.shape[0],batch_size):\n",
    "                temp = %timeit -n1 -r1 -o run_inf(h_input_1, d_input_1, h_output, d_output, stream,brain_tiles[i:i+batch_size,:,:,:])\n",
    "                res.append(temp)\n",
    "                g = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "                p = nvidia_smi.nvmlDeviceGetPowerUsage(handle)\n",
    "                res_gpu.append(g.gpu)\n",
    "                res_mem.append(g.memory)\n",
    "                res_pwr.append(p/1000)\n",
    "\n",
    "            a=0\n",
    "            b=0\n",
    "            w=0\n",
    "            for i in res:\n",
    "                a+=i.average\n",
    "                b+=i.best\n",
    "                w+=i.worst\n",
    "            results_run_engine[path_plan] = (a,b,w)\n",
    "\n",
    "            results_time_gpu_engine[path_plan] = (res_gpu,res_mem,res_pwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "987443da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hovernet_256_8_TF32.plan': (1.0334111978299916,\n",
       "  1.0334111978299916,\n",
       "  1.0334111978299916),\n",
       " 'hovernet_256_8_fp16.plan': (0.43855243222787976,\n",
       "  0.43855243222787976,\n",
       "  0.43855243222787976),\n",
       " 'hovernet_256_16_TF32.plan': (1.0294753164052963,\n",
       "  1.0294753164052963,\n",
       "  1.0294753164052963),\n",
       " 'hovernet_256_16_best.plan': (0.288174559827894,\n",
       "  0.288174559827894,\n",
       "  0.288174559827894),\n",
       " 'hovernet_256_16_fp16.plan': (0.41530073853209615,\n",
       "  0.41530073853209615,\n",
       "  0.41530073853209615)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_run_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4f38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
