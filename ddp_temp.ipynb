{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae21f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbeff05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributed.is_nccl_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8bd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_infer_load(rank, world_size, model, dl):\n",
    "    # create default process group\n",
    "    dist.init_process_group(\"nccl\",init_method='tcp://localhost:23456', rank=rank, world_size=world_size)\n",
    "    # create local model\n",
    "    # model = nn.Linear(10, 10).to(rank)\n",
    "    \n",
    "    # construct DDP model\n",
    "    ddp_model = DDP(model.to(rank), device_ids=[rank])\n",
    "    \n",
    "    # forward pass\n",
    "    outputs = []\n",
    "    for idx,batch in enumerate(dl):\n",
    "        output.append(ddp_model(batch.to(rank)))\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "import models.hovernet.net_desc as net\n",
    "from run_utils.utils import convert_pytorch_checkpoint\n",
    "def getmodel(model_path = 'hovernet_fast_pannuke_type_tf2pytorch.tar'):\n",
    "    \n",
    "    hovernet = net.HoVerNet(nr_types = 6,mode='fast')\n",
    "    saved_state_dict = torch.load(model_path)[\"desc\"]\n",
    "    saved_state_dict = convert_pytorch_checkpoint(saved_state_dict)\n",
    "\n",
    "    hovernet.load_state_dict(saved_state_dict, strict=True)\n",
    "    return hovernet\n",
    "\n",
    "\n",
    "from jp2tileaccesor.multi_res_Tiling import (\n",
    "        SectionProxy, TileAccessor, Span, SectionMemmap, TileIterator\n",
    "    )\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TileDataset(Dataset):\n",
    "    def __init__(self,accessor):\n",
    "        self.accessor = accessor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.accessor)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return torch.Tensor(self.accessor[index][0].copy())\n",
    "    \n",
    "def getdataset():\n",
    "    proxy = SectionProxy()\n",
    "\n",
    "    proxy.check_local_jp2()\n",
    "\n",
    "    if not proxy.check_mmap():\n",
    "        mmap = SectionMemmap(proxy)\n",
    "        mmap.create()\n",
    "\n",
    "    print(proxy.check_mmap())\n",
    "\n",
    "#%%\n",
    "\n",
    "    outsiz = 164,164\n",
    "    insiz = 256,256\n",
    "    hs = insiz[0]-outsiz[0]\n",
    "    padsiz = hs//2\n",
    "    accessor = TileAccessor(proxy,tilespan = Span(*outsiz),padding=padsiz, use_iip=False)\n",
    "\n",
    "#%%\n",
    "\n",
    "    ds = TileDataset(accessor)\n",
    "    return ds\n",
    "\n",
    "def main():\n",
    "    world_size = 8\n",
    "    batch_siz = 64\n",
    "    mdl = getmodel()\n",
    "    ds = getdataset()\n",
    "    dl = DataLoader(ds, batch_size = batch_siz, num_workers=8, drop_last=True)\n",
    "    \n",
    "    mp.spawn(run_infer_load,\n",
    "        args=(world_size, mdl, dl),\n",
    "        nprocs=world_size,\n",
    "        join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./storage/jp2cache/B_37_FB3-SL_570-ST_NISL-SE_1708_lossless.jp2\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'run_infer_load' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e33f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
